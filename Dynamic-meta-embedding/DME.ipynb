{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DME.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "waK1-g4ru5tv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCLCyNpr8My6",
        "outputId": "0ebee420-dce1-4bd1-e1ad-b5a2c4808441"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6Uw-gAq8Ney"
      },
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import string\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZEadH2DCnW6"
      },
      "source": [
        "# **Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvEmaSry_Bo5"
      },
      "source": [
        "pos_sentiment = list()\n",
        "neg_sentiment = list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTtiV5bE_JZt"
      },
      "source": [
        "data_files = ['rt-polarity.pos', 'rt-polarity.neg']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYOCDWQy_WUB"
      },
      "source": [
        "count = 0\n",
        "for file in data_files:\n",
        "  file_descriptor = open(file, 'rb')\n",
        "  lines = file_descriptor.read().decode('utf-8','ignore').splitlines()\n",
        "  for sentence in lines:\n",
        "    if(count == 0):\n",
        "        pos_sentiment.append(sentence)\n",
        "    else:\n",
        "        neg_sentiment.append(sentence)   \n",
        "  count += 1\n",
        "  file_descriptor.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUxWlsTjAedr",
        "outputId": "cddaac7c-0aff-4820-89e6-67b26f38ff72"
      },
      "source": [
        "print(\"The number of sentences in positive sentiment file = \",len(pos_sentiment))\n",
        "print(\"The number of sentences in negative sentiment file = \",len(neg_sentiment))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of sentences in positive sentiment file =  5331\n",
            "The number of sentences in negative sentiment file =  5331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKlP6IpjBVSx"
      },
      "source": [
        "X_train = pos_sentiment[:4500] + neg_sentiment[:4500]\n",
        "\n",
        "X_test = pos_sentiment[4500:] + neg_sentiment[4500:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NzZdwirB4Io"
      },
      "source": [
        "y_train = [0]*4500 + [1]*4500\n",
        "\n",
        "y_test = [0]*831 + [1]*831"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5WheypsCGKa",
        "outputId": "10feb1e3-d993-4292-9dd1-7e6d048fc2cb"
      },
      "source": [
        "print(\"The number of sentences in X_train = \",len(X_train))\n",
        "print(\"The number of sentences in X_test = \",len(X_test))\n",
        "\n",
        "print(\"length of y_train = \", len(y_train))\n",
        "print(\"length of y_test = \", len(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of sentences in X_train =  9000\n",
            "The number of sentences in X_test =  1662\n",
            "length of y_train =  9000\n",
            "length of y_test =  1662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9043_Ip1AEa"
      },
      "source": [
        "# printing all the words of length less than 3 except no\n",
        "lists = []\n",
        "for text in X_train:\n",
        "  words =[w for w in text.split() if len(w)<3 and w not in ['no']]\n",
        "  lists.append(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFXuyU0FLGF9"
      },
      "source": [
        "# **Preprocessing**\n",
        "\n",
        "\n",
        "*   **Replacing contractions with their meanings** \n",
        "*   **Removing all non-alphanumeric and symbols**\n",
        "*   **Removing the words of length less than 3 from the text except no**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNIoFTMi02zS",
        "outputId": "91f3f54b-c038-4aed-edd1-52359166fba3"
      },
      "source": [
        "!pip install contractions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.0.52)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.21)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.3.0)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4ZTzwunLTN5"
      },
      "source": [
        "import contractions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2TSV7mGIpRf"
      },
      "source": [
        "pp_X_train = list()\n",
        "alphaPattern = \"[^a-z0-9<>]\"\n",
        "for text in X_train:\n",
        "  pp_text = contractions.fix(text)\n",
        "  pp_text = re.sub(alphaPattern, ' ', pp_text)\n",
        "  pp_text = ' '.join([w for w in pp_text.split() if len(w)>2 and w not in ['no']])\n",
        "  pp_X_train.append(pp_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOP8H-kp2p_L"
      },
      "source": [
        "pp_X_test = list()\n",
        "alphaPattern = \"[^a-z0-9<>]\"\n",
        "for text in X_test:\n",
        "  pp_text = contractions.fix(text)\n",
        "  pp_text = re.sub(alphaPattern, ' ', pp_text)\n",
        "  pp_text = ' '.join([w for w in pp_text.split() if len(w)>2 and w not in ['no']])\n",
        "  pp_X_test.append(pp_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wv1_jjIcLuyf",
        "outputId": "a05d3265-02d8-4d69-ef2a-1f5e8e81a079"
      },
      "source": [
        "pp_X_train[4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'emerges something rare issue movie that honest and keenly observed that does not feel like one'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r08rkHTPL6bV",
        "outputId": "673192fe-dfee-4878-c779-397aaca7e7f3"
      },
      "source": [
        "len(pp_X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9000"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KtzC0jxsIjf",
        "outputId": "32b4ae38-3530-41df-d3b4-7f68b67b1d5c"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne8dEG0osOP_",
        "outputId": "d4b0a750-ed97-45a5-a50a-b2c9630b26a0"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Dt-dIwH6iXE",
        "outputId": "06d2b818-ebbb-41b6-b0d6-d07e85df2412"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzSB3pNKrg0t"
      },
      "source": [
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "lm_X_train = []\n",
        "for s in pp_X_train:\n",
        "  sent = []\n",
        "  for word in word_tokenize(s):\n",
        "    sent.append(lemmatizer.lemmatize(word))\n",
        "  lm_X_train.append(\" \".join([i for i in sent]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpRx5dz-25kj"
      },
      "source": [
        "lm_X_test = []\n",
        "for s in pp_X_test:\n",
        "  sent = []\n",
        "  for word in word_tokenize(s):\n",
        "    sent.append(lemmatizer.lemmatize(word))\n",
        "  lm_X_test.append(\" \".join([i for i in sent]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRavLOaitM9z",
        "outputId": "96697475-ea02-42df-9d1a-d95d1cd1d721"
      },
      "source": [
        "type(lm_X_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZw8H1PusxLc"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "preprocessed_X_train = []\n",
        "for sentence in lm_X_train:\n",
        "    preprocessed_X_train.append(\" \".join([stemmer.stem(i) for i in sentence.split()])) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJBMvCpqsSwR",
        "outputId": "625465de-4556-483a-bf7a-1550e9002d1b"
      },
      "source": [
        "type(preprocessed_X_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAzr9ihb4fMI"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words.remove('not')\n",
        "stop_words.remove('but')\n",
        "\n",
        "final_X_train = []\n",
        "for sentence in lm_X_train:\n",
        "    final_X_train.append(\" \".join([words for words in sentence.split() if not words in stop_words]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "im31_VAr6sy8",
        "outputId": "3677d9e9-4a0e-4530-86ba-a285475b281f"
      },
      "source": [
        "len(final_X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9000"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYOFH4pV3KVd"
      },
      "source": [
        "final_X_test = []\n",
        "for sentence in lm_X_test:\n",
        "    final_X_test.append(\" \".join([words for words in sentence.split() if not words in stop_words]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkLiRtES_y-K"
      },
      "source": [
        "## **Glove Embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEt2TUBT50vT",
        "outputId": "bcb1af51-9fa1-414c-a597-e5db465e5369"
      },
      "source": [
        "import numpy as np\n",
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "\n",
        "f = open('/content/drive/MyDrive/IISc_3rd_sem/DLNLP/Assignment_3/glove.6B.100d.txt')\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\n",
        "  embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.'% len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Reh1mVUouLK",
        "outputId": "9ed1a71c-567e-450f-8364-21125405dc81"
      },
      "source": [
        "print(embeddings_index['the'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.038194 -0.24487   0.72812  -0.39961   0.083172  0.043953 -0.39141\n",
            "  0.3344   -0.57545   0.087459  0.28787  -0.06731   0.30906  -0.26384\n",
            " -0.13231  -0.20757   0.33395  -0.33848  -0.31743  -0.48336   0.1464\n",
            " -0.37304   0.34577   0.052041  0.44946  -0.46971   0.02628  -0.54155\n",
            " -0.15518  -0.14107  -0.039722  0.28277   0.14393   0.23464  -0.31021\n",
            "  0.086173  0.20397   0.52624   0.17164  -0.082378 -0.71787  -0.41531\n",
            "  0.20335  -0.12763   0.41367   0.55187   0.57908  -0.33477  -0.36559\n",
            " -0.54857  -0.062892  0.26584   0.30205   0.99775  -0.80481  -3.0243\n",
            "  0.01254  -0.36942   2.2167    0.72201  -0.24978   0.92136   0.034514\n",
            "  0.46745   1.1079   -0.19358  -0.074575  0.23353  -0.052062 -0.22044\n",
            "  0.057162 -0.15806  -0.30798  -0.41625   0.37972   0.15006  -0.53212\n",
            " -0.2055   -1.2526    0.071624  0.70565   0.49744  -0.42063   0.26148\n",
            " -1.538    -0.30223  -0.073438 -0.28312   0.37104  -0.25217   0.016215\n",
            " -0.017099 -0.38984   0.87424  -0.72569  -0.51058  -0.52028  -0.1459\n",
            "  0.8278    0.27062 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBE-T3dICTTY",
        "outputId": "cfc1a96b-22a4-4b9e-c206-d0d7d239f471"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer_obj = Tokenizer()\n",
        "tokenizer_obj.fit_on_texts(lm_X_train)\n",
        "sequences = tokenizer_obj.texts_to_sequences(lm_X_train)\n",
        "\n",
        "#pad sequences\n",
        "word_index = tokenizer_obj.word_index\n",
        "print(\"number of unique tokens = \", len(word_index))\n",
        "\n",
        "max_len = max([len(s.split()) for s in lm_X_train])\n",
        "\n",
        "padded_sequences = pad_sequences(sequences, maxlen = max_len)\n",
        "#vocab_size = len(tokenizer_obj.word_index)+1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of unique tokens =  15183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-3I08nx3vUX",
        "outputId": "b9ef3958-80c9-413b-baed-6b872f294a24"
      },
      "source": [
        "tokenizer_obj.fit_on_texts(final_X_test)\n",
        "test_sequences = tokenizer_obj.texts_to_sequences(final_X_test)\n",
        "\n",
        "#pad sequences\n",
        "test_word_index = tokenizer_obj.word_index\n",
        "print(\"number of unique tokens = \", len(test_word_index))\n",
        "\n",
        "test_max_len = max([len(s.split()) for s in final_X_test])\n",
        "\n",
        "test_padded_sequences = pad_sequences(test_sequences, maxlen = test_max_len)\n",
        "#vocab_size = len(tokenizer_obj.word_index)+1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of unique tokens =  16335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GseQyB8vdzs",
        "outputId": "a4204dc7-f03e-4a79-f59f-0a3bf07df638"
      },
      "source": [
        "word_index['xxx']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1676"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwcaonRdmub_",
        "outputId": "14a6c10f-36dd-4671-fd6e-3def3e76fb18"
      },
      "source": [
        "max_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GdoFhsGlZBd"
      },
      "source": [
        "num_words = len(word_index) + 1\n",
        "glove_matrix = np.zeros((num_words, 100))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "  if i > num_words:\n",
        "    continue\n",
        "  glove_vector = embeddings_index.get(word)\n",
        "\n",
        "  \"\"\"if glove_vector is None:\n",
        "    print(word)\"\"\"\n",
        "\n",
        "  if glove_vector is not None:\n",
        "    glove_matrix[i] = glove_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne6q_VonBA87",
        "outputId": "ff7aded8-66fd-4bb8-d2bb-4df12e086070"
      },
      "source": [
        "glove_matrix[1791]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-3.39940004e-03,  5.16589999e-01,  6.48639977e-01, -4.14579988e-01,\n",
              "       -3.50059986e-01,  2.34390005e-01, -1.31390005e-01, -3.65469992e-01,\n",
              "        7.71539986e-01,  2.07020000e-01,  4.08880003e-02,  6.93970025e-01,\n",
              "       -4.73910004e-01, -6.16250001e-03,  4.10549998e-01,  8.14680010e-02,\n",
              "       -7.61810005e-01, -8.90360028e-02,  9.59190011e-01,  3.08910012e-01,\n",
              "        4.41740006e-01,  3.16489995e-01,  5.70309997e-01, -3.64520013e-01,\n",
              "        6.83329999e-02,  3.56319994e-02, -4.29100007e-01,  8.55709985e-02,\n",
              "       -3.60170007e-01, -2.84240007e-01, -2.01590002e-01, -2.15680003e-02,\n",
              "       -2.89669991e-01, -3.37909997e-01, -5.20850003e-01,  3.93020004e-01,\n",
              "       -1.82569996e-01, -5.90709984e-01,  2.22509995e-01, -5.40390015e-01,\n",
              "        6.79050028e-01,  3.55740011e-01, -5.22040009e-01,  1.06430002e-01,\n",
              "       -4.38279986e-01,  7.91099966e-02,  6.10360026e-01,  2.96480000e-01,\n",
              "       -1.50779998e-02, -4.58009988e-01,  2.69400001e-01,  9.00010020e-02,\n",
              "        5.91660023e-01, -1.66500002e-01, -3.47770005e-01,  1.91949993e-01,\n",
              "        5.87050021e-01,  1.32090002e-01, -5.29659986e-01, -5.22610009e-01,\n",
              "       -2.28269994e-01,  3.47689986e-01, -2.21070006e-01,  2.34830007e-02,\n",
              "        2.32529998e-01, -5.01439989e-01,  5.85889995e-01,  2.25610007e-02,\n",
              "       -5.92119992e-01, -4.95240003e-01, -6.14809990e-01, -4.44110006e-01,\n",
              "        4.86000001e-01,  2.47549996e-01, -3.76159996e-01, -2.12129995e-01,\n",
              "       -6.62949984e-04,  8.30669999e-02, -2.36149997e-01, -4.78810012e-01,\n",
              "       -4.38169986e-01, -8.88890028e-02,  1.46459997e-01,  2.69580007e-01,\n",
              "       -1.04050004e+00,  8.01199973e-01,  2.15939999e-01,  8.38370025e-02,\n",
              "       -2.46900007e-01, -8.59009996e-02,  2.53950000e-01,  6.76869988e-01,\n",
              "       -3.66719991e-01,  1.56000003e-01,  6.35519981e-01, -3.31900001e-01,\n",
              "       -6.97090030e-01, -3.01770002e-01, -5.08690000e-01,  8.22790027e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_PWi5E3vUp3",
        "outputId": "0add831b-f7c6-4823-a32d-5caca0d2aed9"
      },
      "source": [
        "embeddings_index['xxx']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.3687  ,  0.41059 ,  1.565   , -0.1187  , -0.32459 ,  0.39897 ,\n",
              "        0.35587 , -0.17277 ,  0.38739 ,  0.51668 ,  0.090743,  0.23561 ,\n",
              "       -0.85961 , -0.50437 , -0.17357 ,  0.35341 ,  0.17042 , -0.299   ,\n",
              "       -0.5052  , -0.74482 ,  0.43591 , -0.38928 , -0.89028 ,  1.2465  ,\n",
              "        0.13994 , -0.30271 ,  0.58277 ,  0.33706 ,  0.36108 ,  0.14702 ,\n",
              "        0.51448 , -0.63922 ,  0.028113, -0.53355 , -0.45277 ,  0.13799 ,\n",
              "       -0.91906 ,  0.048266, -0.081248,  0.24234 ,  0.24568 ,  0.3748  ,\n",
              "       -0.72479 , -0.87584 ,  0.003958,  0.19572 , -1.151   , -0.22924 ,\n",
              "        0.11799 , -0.66704 ,  0.08724 ,  0.48058 ,  0.14039 , -0.18884 ,\n",
              "       -1.0674  , -0.051663, -0.16704 ,  0.27572 ,  0.25151 ,  0.48217 ,\n",
              "       -1.0164  ,  0.21111 , -0.27002 , -0.3216  ,  0.39403 ,  0.20284 ,\n",
              "        0.33473 ,  0.20013 , -0.25163 ,  0.65423 ,  0.76122 , -0.1537  ,\n",
              "       -0.52411 , -0.026835,  0.3317  ,  0.28225 ,  0.042049,  0.58157 ,\n",
              "       -0.41904 , -0.63762 , -0.79662 , -0.99222 , -0.22536 ,  0.24783 ,\n",
              "       -0.29843 ,  0.36125 , -0.3721  , -0.81558 , -0.035106,  0.10647 ,\n",
              "       -0.051978,  0.50529 , -0.43127 , -0.49167 , -0.01375 , -0.62282 ,\n",
              "        0.95813 , -0.5376  , -0.6886  ,  0.38651 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6XkfzhOxike"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layer import Dense, Embedding, LSTM, GRU\n",
        "from keras.layes.embeddings import Embedding\n",
        "from keras.initializers import Constant\n",
        "\n",
        "model = Sequential()\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            EMBEDDING_DIM,\n",
        "                            embeddings_initializer = Constant(embedding_matrix),\n",
        "                            input_length=max_length,\n",
        "                            trainable = False)\n",
        "\n",
        "model.add(embedding_layer)\n",
        "model.add(LSTM(units=32, dropout=0.2, recurrent_dropout = 0.2))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkmzR8TExSXT"
      },
      "source": [
        "## **Word2Vec**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHqZpptRvopp",
        "outputId": "f0af1ddf-01a6-4e48-e65d-696008ca66a5"
      },
      "source": [
        "import gensim.downloader\n",
        "\n",
        "print(list(gensim.downloader.info()['models'].keys()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDVKr89mx_Ry",
        "outputId": "7e55e19a-f77b-45db-9846-f92a7eeba719"
      },
      "source": [
        "Word2Vec_model = gensim.downloader.load('word2vec-google-news-300')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeqEyL6o1vrD"
      },
      "source": [
        "import pickle\n",
        "w2v_embedding_dict = open(\"w2v_dict.pkl\", \"wb\")\n",
        "pickle.dump(Word2Vec_model, w2v_embedding_dict)\n",
        "w2v_embedding_dict.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppdstfnq6_J4"
      },
      "source": [
        "import pickle\n",
        "w2v_embed = open(\"/content/w2v_dict.pkl\", \"rb\")\n",
        "w2v_embed_dict = pickle.load(w2v_embed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M7rVsizyfjU"
      },
      "source": [
        "word2vec_matrix = np.zeros((num_words, 300))\n",
        "count = 0\n",
        "for word, i in word_index.items():\n",
        "  if i > num_words:\n",
        "    continue\n",
        "\n",
        "  if word not in w2v_embed_dict.vocab:\n",
        "    count += 1\n",
        "    continue\n",
        "\n",
        "  word2vec_vector = w2v_embed_dict[word]\n",
        "\n",
        "  \"\"\"if glove_vector is None:\n",
        "    print(word)\"\"\"\n",
        "\n",
        "  if word2vec_vector is not None:\n",
        "    word2vec_matrix[i] = word2vec_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy92WIn_2cPM",
        "outputId": "bd5279a3-2000-4775-9e4e-4eb3f5e3d120"
      },
      "source": [
        "count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1617"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RT5AupR_F5q"
      },
      "source": [
        "## **FastText**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULeRTcey-YWn",
        "outputId": "a51f1673-7bef-4e09-dbc1-5e7abbf73ae0"
      },
      "source": [
        "import gensim.downloader\n",
        "fastText_embed = gensim.downloader.load('fasttext-wiki-news-subwords-300')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 958.5/958.4MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "835wCLWI_Xs3"
      },
      "source": [
        "import pickle\n",
        "fastText_embedding_dict = open(\"fastText_dict.pkl\", \"wb\")\n",
        "pickle.dump(fastText_embed, fastText_embedding_dict)\n",
        "fastText_embedding_dict.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvP4JTSmDTxx"
      },
      "source": [
        "fastText_embed = open(\"/content/fastText_dict.pkl\", \"rb\")\n",
        "fastText_embed_dict = pickle.load(fastText_embed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUTBIXaHDkjU"
      },
      "source": [
        "fastText_matrix = np.zeros((num_words, 300))\n",
        "count = 0\n",
        "for word, i in word_index.items():\n",
        "  if i > num_words:\n",
        "    continue\n",
        "\n",
        "  if word not in  fastText_embed_dict.vocab:\n",
        "    count += 1\n",
        "    continue\n",
        "\n",
        "  fastText_vector = fastText_embed_dict[word]\n",
        "\n",
        "  \"\"\"if glove_vector is None:\n",
        "    print(word)\"\"\"\n",
        "\n",
        "  if fastText_vector is not None:\n",
        "    fastText_matrix[i] = fastText_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFNvKiJsD6Ey",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc1faf98-c5fa-495f-8389-da0a59042540"
      },
      "source": [
        "count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1153"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiB8RMLTkbdK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1GiYAkkmUuH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M3dW_ofmUxt"
      },
      "source": [
        "## This block is to create the embedding layer\n",
        "\n",
        "vocab_size = glove_matrix.shape[0]\n",
        "vector_size = glove_matrix.shape[1]\n",
        " \n",
        "embedding_glove = torch.nn.Embedding(num_embeddings = vocab_size,embedding_dim=vector_size)\n",
        "\n",
        "embedding_glove.weight = torch.nn.Parameter(torch.tensor(glove_matrix, dtype=torch.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgjeiI1rmnnW"
      },
      "source": [
        "embedding_glove.weight.requires_grad=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6Pj5lQkmswD",
        "outputId": "90f99dcc-2d59-478f-9b35-c8e5517694b5"
      },
      "source": [
        "embedding_vec = embedding_glove(torch.LongTensor([[0,1]]))\n",
        "print(embedding_glove)\n",
        "print(embedding_vec.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(15184, 100)\n",
            "torch.Size([1, 2, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRWUrlqQmszs"
      },
      "source": [
        "vocab_size = word2vec_matrix.shape[0]\n",
        "vector_size = word2vec_matrix.shape[1]\n",
        " \n",
        "embedding_word2vec = nn.Embedding(num_embeddings = vocab_size, embedding_dim = vector_size)\n",
        "\n",
        "embedding_word2vec.weight=torch.nn.Parameter(torch.tensor(word2vec_matrix, dtype=torch.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh2JUeXFnnE6"
      },
      "source": [
        "embedding_word2vec.weight.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1rMKoFgnWv5"
      },
      "source": [
        "vocab_size = fastText_matrix.shape[0]\n",
        "vector_size = fastText_matrix.shape[1]\n",
        " \n",
        "embedding_fasttext = nn.Embedding(num_embeddings=vocab_size,embedding_dim=vector_size)\n",
        "\n",
        "embedding_fasttext.weight = torch.nn.Parameter(torch.tensor(fastText_matrix,dtype=torch.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahobS8kXniuL"
      },
      "source": [
        "embedding_fasttext.weight.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuqDR8-Xni22"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLqWLuMdnuel"
      },
      "source": [
        "\n",
        "class no_DME(torch.nn.Module):\n",
        "    def __init__(self , embedding_dim, hidden_dim):\n",
        "        super(no_DME, self).__init__()\n",
        "\n",
        "\n",
        "        ## Here we only have one embedding. We can choose embedding from 1. embedding_glove , 2. embedding_word2vec , 3. embedding_fasttext\n",
        "        self.embedding = embedding_word2vec\n",
        "\n",
        "        ## Now we will have a lstm to encode a sentence\n",
        "        self.lstm = nn.LSTM(embedding_dim , hidden_dim)\n",
        "\n",
        "        ### Add the below line if you want bidirectional model\n",
        "        ## self.lstm = nn.LSTM(embedding_dim , hidden_dim , bidirectional=bidirectional)\n",
        "\n",
        "        ## Now a FFNN which will Find the class of the sentence\n",
        "\n",
        "        ## I have 2 choices here 1. Taking the last layer of lstm as input which will represent the sentence\n",
        "        ## 2. Or i could take all the hidden stage output but if we are taking this then we will have to fix the \n",
        "        ## Length of the sentence. I could do it . Maybe if the performance for this is very low\n",
        "\n",
        "        self.linear_relu_stack = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_dim, 512),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 1),\n",
        "            torch.nn.Sigmoid() ## So that this will give the probability of being label 1\n",
        "        )\n",
        "\n",
        "    ## x is a tensor representing a sentence. x could be in batches but i am taking it to be only 1 sentence\n",
        "    def forward(self, x):\n",
        "\n",
        "        ## First get the embedding from the embedding layer\n",
        "\n",
        "        first = self.embedding(x.long())\n",
        "\n",
        "        lstm_out, _ = self.lstm(first.view(len(x), 1, -1))\n",
        "        \n",
        "        ## print(\"shape of lstm_out = \" , lstm_out[-1][0].shape)\n",
        "\n",
        "        prob_of_label1 = self.linear_relu_stack(lstm_out[-1][0])\n",
        "\n",
        "        ## Let sentence_context is the output of lstm\n",
        "        return prob_of_label1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfwYWGnYnuns"
      },
      "source": [
        "## Making the architecture for Dynamic Meta Embedding\n",
        "class DME(torch.nn.Module):\n",
        "    def __init__(self , glove_embedding_dim , word2vec_embedding_dim , fasttext_embedding_dim , common_dim , hidden_dim):\n",
        "        super(DME, self).__init__()\n",
        "\n",
        "        ## These are the 3 embedding layers\n",
        "        ## See once its gradient is Freezed or not\n",
        "        self.embedding_glove_ = embedding_glove\n",
        "        self.embedding_word2vec_ = embedding_word2vec\n",
        "        self.embedding_fasttext_ = embedding_fasttext\n",
        "\n",
        "        ## Now they will pass through separate linear layers for themselves\n",
        "        self.linear1 = nn.Linear( glove_embedding_dim , common_dim )\n",
        "        self.linear2 = nn.Linear( word2vec_embedding_dim , common_dim )\n",
        "        self.linear3 = nn.Linear( fasttext_embedding_dim , common_dim )\n",
        "\n",
        "        ## Now they will pass through a single layer one by one\n",
        "        ## This will compute the attention to be given for each embedding\n",
        "\n",
        "        self.linear_sigmoid_stack = nn.Sequential(\n",
        "            nn.Linear( common_dim , 1 ),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "  \n",
        "        ## Now we will have a lstm to encode a sentence\n",
        "        self.lstm = nn.LSTM(common_dim , hidden_dim , bidirectional = False) \n",
        "        ## Now a FFNN which will Find the class of the sentence\n",
        "\n",
        "        ## I have 2 choices here 1. Taking the last layer of lstm as input which will represent the sentence\n",
        "        ## 2. Or i could take all the hidden stage output but if we are taking this then we will have to fix the \n",
        "        ## Length of the sentence. I could do it . Maybe if the performance for this is very low\n",
        "\n",
        "        self.linear_relu_stack = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_dim, 512),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 1),\n",
        "            torch.nn.Sigmoid() ## So that this will give the probability of being label 1\n",
        "        )\n",
        "\n",
        "\n",
        "        '''\n",
        "        Use this if 1 layer doesnot give proper output\n",
        "\n",
        "        self.linear_relu_stack = torch.nn.Sequential(\n",
        "            torch.nn.Linear(input_size, 512),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 256),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, 3)\n",
        "        )\n",
        "        '''\n",
        "\n",
        "    ## x is a tensor representing a sentence. x could be in batches but i am taking it to be only 1 sentence\n",
        "    def forward(self, x):\n",
        "\n",
        "        ## First get the embedding from each embedding layer\n",
        "        ## If given in batches the embedding layer assumes the sequeneces should have equal length\n",
        "\n",
        "        ## Now i am assuming that i am giving input one sequence only\n",
        "\n",
        "        first = self.embedding_glove_(x.long())\n",
        "        second = self.embedding_word2vec_(x.long())\n",
        "        third = self.embedding_fasttext_(x.long())\n",
        "\n",
        "        '''\n",
        "        print(\"Shape of first = \" , first.shape)\n",
        "        print(\"Shape of second = \" , second.shape)\n",
        "        print(\"Shape of third = \" , third.shape)\n",
        "        '''\n",
        "\n",
        "        first_l = self.linear1(first)\n",
        "        second_l = self.linear2(second)\n",
        "        third_l = self.linear3(third)\n",
        "\n",
        "        '''\n",
        "        print(\"Shape of first_l = \" , first_l.shape)\n",
        "        print(\"Shape of second_l = \" , second_l.shape)\n",
        "        print(\"Shape of third_l = \" , third_l.shape)\n",
        "        '''\n",
        "\n",
        "        ## Now that they are passed through the linear layer \n",
        "        ## It is slighlty tricky how i would apply a common layer to all\n",
        "\n",
        "        ## I will get here the sentence\n",
        "        ## Now how do i find the encoding of the \n",
        "        \n",
        "        attn1 = self.linear_sigmoid_stack(first_l)\n",
        "        attn2 = self.linear_sigmoid_stack(second_l)\n",
        "        attn3 = self.linear_sigmoid_stack(third_l)\n",
        "\n",
        "        '''\n",
        "        print(\"Shape of attn1 = \" , attn1.shape)\n",
        "        print(\"Shape of attn2 = \" , attn2.shape)\n",
        "        print(\"Shape of attn3 = \" , attn3.shape)\n",
        "        '''\n",
        "\n",
        "        ## I have done this assuming that the x contains only 1 string\n",
        "        ## For batches i have to change some things here\n",
        "\n",
        "        embed = torch.mul( first_l , attn1.view(len(attn1))[: , None] ) + torch.mul( second_l , attn2.view(len(attn2))[: , None] ) + torch.mul( third_l , attn3.view(len(attn3))[: , None] )\n",
        "\n",
        "        ## print(\"The shape of embed = \" , embed.shape)\n",
        "\n",
        "        ## Now this is the embedding of the sentence\n",
        "        ## Now i will pass the embed into the lstm\n",
        "        ## ANd will take only the last hidden output\n",
        "\n",
        "        lstm_out, _ = self.lstm(embed.view(len(x), 1, -1))\n",
        "        \n",
        "        ## print(\"shape of lstm_out = \" , lstm_out[-1][0].shape)\n",
        "\n",
        "        prob_of_label1 = self.linear_relu_stack(lstm_out[-1][0])\n",
        "\n",
        "        ## Let sentence_context is the output of lstm\n",
        "        return prob_of_label1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "892X7QrXoel9"
      },
      "source": [
        "## Parameters are - globe_embedding_dim , word2vec_embedding_dim , fasttext_embedding_dim , common_dim , hidden_dim\n",
        "import torch.optim as optim\n",
        "model = DME( 100 , 300 , 300 , 100 , 100 )\n",
        "\n",
        "loss_function = nn.BCELoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr97JL4-oew1"
      },
      "source": [
        "## Run this code if doing the vanilla model\n",
        "import torch.optim as optim\n",
        "model = no_DME( 300 , 128 )\n",
        "\n",
        "loss_function = nn.BCELoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9cKnbygkc1f"
      },
      "source": [
        "# split the data into training set and the validation set\n",
        "\n",
        "\"\"\"validation_split = 0.2\n",
        "\n",
        "indices = np.arange(padded_sequences.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "padded_sequences = padded_sequences[indices]\n",
        "labels =  np.array(y_train,dtype = np.int32)\n",
        "\n",
        "labels = labels[indices]\n",
        "\n",
        "\n",
        "classes = 2\n",
        "class_array = np.eye(classes)[labels]\n",
        "\n",
        "num_validation_samples = int(validation_split * padded_sequences.shape[0])\n",
        "\n",
        "X_train_pad = padded_sequences[:-num_validation_samples]\n",
        "y_train_final = class_array[:-num_validation_samples]\n",
        "X_validate_pad = padded_sequences[-num_validation_samples:]\n",
        "y_validate_final = class_array[-num_validation_samples:]\"\"\"\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "x_tr_seq, y_train = shuffle(padded_sequences, y_train)\n",
        "\n",
        "m = int(0.8*len(y_train))\n",
        "X_train_pad = x_tr_seq[:m]\n",
        "X_validate_pad = x_tr_seq[m:]\n",
        "y_validate_final = y_train[m:]\n",
        "y_train_final = y_train[:m]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4AUyRTsnufT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "034fe7e0-926d-4784-89e5-1b6d64b18a9f"
      },
      "source": [
        "print(X_validate_pad.shape)\n",
        "print(X_train_pad.shape)\n",
        "print(len(y_train_final))\n",
        "print(len(y_validate_final))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1800, 41)\n",
            "(7200, 41)\n",
            "7200\n",
            "1800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3ZR48Q94me-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQOVt1Az4m4S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j96fhOlws88U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wslTphumofBz"
      },
      "source": [
        "train_data_tensor = torch.from_numpy(X_train_pad)\n",
        "validation_data_tensor = torch.from_numpy(X_validate_pad)\n",
        "\n",
        "train_label_tensor = torch.from_numpy(np.array(y_train_final))\n",
        "validation_label_tensor = torch.from_numpy(np.array(y_validate_final))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4u9ea4stIKs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFc-nZ7O4u5v"
      },
      "source": [
        "test_data_tensor = torch.from_numpy((test_padded_sequences))\n",
        "test_label_tensor = torch.from_numpy(np.array(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amSGH9LvtIx-"
      },
      "source": [
        "## It will take the dataset as list tensor input and the target as a tensor output and it'll compute the accuracy\n",
        "## Also returns the loss \n",
        "\n",
        "def accuracy(dataset , target):\n",
        "  total_loss = 0.0\n",
        "  correct = 0\n",
        "  for i in range(len(dataset)):\n",
        "    data_tensor = dataset[i]\n",
        "    label_tensor = target[i].view(1)\n",
        "\n",
        "    if (len(data_tensor) == 0):\n",
        "      if label_tensor.item() == 1:\n",
        "        correct = correct + 1\n",
        "      continue\n",
        "\n",
        "    with torch.no_grad():\n",
        "      pred = model(data_tensor)\n",
        "\n",
        "      ##print(pred.shape , label_tensor.shape)\n",
        "\n",
        "      if (pred >= 0.5 and label_tensor.item() == 1):\n",
        "        correct = correct + 1\n",
        "      \n",
        "      if (pred < 0.5 and label_tensor.item() == 0):\n",
        "        correct = correct + 1\n",
        "\n",
        "      loss = loss_function(pred , label_tensor.float())\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      if (i%500 == 0):\n",
        "        print(\"Loss at \" , i , \"th iteration is : \" , loss.item())\n",
        "  \n",
        "  return total_loss , correct / len(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpIhm3PmtI1_",
        "outputId": "49af0aa1-edd2-47dd-a67e-9c97bf4e887a"
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "training_acc = []\n",
        "validation_acc = []\n",
        "\n",
        "test_acc = []\n",
        "test_loss = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  loss_per_epoch = 0\n",
        "  print(\"Epoch \" , epoch , \" is starting...\")\n",
        "  print(\"__________________________________\")\n",
        "\n",
        "  ## Now i will try to feed each of the sentence into the \n",
        "  for i in range(len(train_data_tensor)):\n",
        "    data_tensor = train_data_tensor[i]\n",
        "    label_tensor = train_label_tensor[i].view(1)\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    pred = model(data_tensor)\n",
        "\n",
        "    ##print(pred.shape , label_tensor.shape)\n",
        "\n",
        "    loss = loss_function(pred , label_tensor.float())\n",
        "    loss_per_epoch = loss_per_epoch + loss.item()\n",
        "\n",
        "    if (i%500 == 0):\n",
        "      print(\"Loss at \" , i , \"th iteration is : \" , loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  print(\"Total loss in this epoch is  = \" , loss_per_epoch)\n",
        "\n",
        "  val_loss , val_acc = accuracy( validation_data_tensor , validation_label_tensor )\n",
        "  validation_loss.append(val_loss)\n",
        "  validation_acc.append(val_acc)\n",
        "  train_loss , train_acc = accuracy( train_data_tensor , train_label_tensor )\n",
        "  training_loss.append(train_loss)\n",
        "  training_acc.append(train_acc)\n",
        "  \"\"\"tes_loss , tes_acc = accuracy( test_data_tensor , test_label_tensor )\n",
        "  test_loss.append(tes_loss)\n",
        "  test_acc.append(tes_acc)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  0  is starting...\n",
            "__________________________________\n",
            "Loss at  0 th iteration is :  0.6879064440727234\n",
            "Loss at  500 th iteration is :  0.8191784620285034\n",
            "Loss at  1000 th iteration is :  0.7234711050987244\n",
            "Loss at  1500 th iteration is :  0.7361924648284912\n",
            "Loss at  2000 th iteration is :  0.7187933921813965\n",
            "Loss at  2500 th iteration is :  0.6952921152114868\n",
            "Loss at  3000 th iteration is :  0.6876242160797119\n",
            "Loss at  3500 th iteration is :  0.6641831398010254\n",
            "Loss at  4000 th iteration is :  0.7196163535118103\n",
            "Loss at  4500 th iteration is :  0.7082860469818115\n",
            "Loss at  5000 th iteration is :  0.6884216070175171\n",
            "Loss at  5500 th iteration is :  0.7132075428962708\n",
            "Loss at  6000 th iteration is :  0.7121844291687012\n",
            "Loss at  6500 th iteration is :  0.6873313188552856\n",
            "Loss at  7000 th iteration is :  0.6890898942947388\n",
            "Total loss in this epoch is  =  5001.84615072608\n",
            "Loss at  0 th iteration is :  0.6911307573318481\n",
            "Loss at  500 th iteration is :  0.6906081438064575\n",
            "Loss at  1000 th iteration is :  0.6911380290985107\n",
            "Loss at  1500 th iteration is :  0.6910734176635742\n",
            "Loss at  0 th iteration is :  0.6894436478614807\n",
            "Loss at  500 th iteration is :  0.6951526999473572\n",
            "Loss at  1000 th iteration is :  0.6951576471328735\n",
            "Loss at  1500 th iteration is :  0.695380687713623\n",
            "Loss at  2000 th iteration is :  0.695248544216156\n",
            "Loss at  2500 th iteration is :  0.696025013923645\n",
            "Loss at  3000 th iteration is :  0.6955952048301697\n",
            "Loss at  3500 th iteration is :  0.6957104802131653\n",
            "Loss at  4000 th iteration is :  0.6951543092727661\n",
            "Loss at  4500 th iteration is :  0.6952245235443115\n",
            "Loss at  5000 th iteration is :  0.6952192783355713\n",
            "Loss at  5500 th iteration is :  0.6911143660545349\n",
            "Loss at  6000 th iteration is :  0.6952101588249207\n",
            "Loss at  6500 th iteration is :  0.6835951805114746\n",
            "Loss at  7000 th iteration is :  0.695190966129303\n",
            "Epoch  1  is starting...\n",
            "__________________________________\n",
            "Loss at  0 th iteration is :  0.6894436478614807\n",
            "Loss at  500 th iteration is :  0.750410795211792\n",
            "Loss at  1000 th iteration is :  0.7221876978874207\n",
            "Loss at  1500 th iteration is :  0.6995226144790649\n",
            "Loss at  2000 th iteration is :  0.6903407573699951\n",
            "Loss at  2500 th iteration is :  0.6857922673225403\n",
            "Loss at  3000 th iteration is :  0.6769554018974304\n",
            "Loss at  3500 th iteration is :  0.663842499256134\n",
            "Loss at  4000 th iteration is :  0.6933946013450623\n",
            "Loss at  4500 th iteration is :  0.6993806958198547\n",
            "Loss at  5000 th iteration is :  0.6833524107933044\n",
            "Loss at  5500 th iteration is :  0.7000398635864258\n",
            "Loss at  6000 th iteration is :  0.7071433663368225\n",
            "Loss at  6500 th iteration is :  0.6933770179748535\n",
            "Loss at  7000 th iteration is :  0.6578550338745117\n",
            "Total loss in this epoch is  =  4997.601966649294\n",
            "Loss at  0 th iteration is :  0.692164421081543\n",
            "Loss at  500 th iteration is :  0.690822422504425\n",
            "Loss at  1000 th iteration is :  0.6919741630554199\n",
            "Loss at  1500 th iteration is :  0.692176103591919\n",
            "Loss at  0 th iteration is :  0.6926306486129761\n",
            "Loss at  500 th iteration is :  0.6942448616027832\n",
            "Loss at  1000 th iteration is :  0.6965146660804749\n",
            "Loss at  1500 th iteration is :  0.6940299272537231\n",
            "Loss at  2000 th iteration is :  0.6944883465766907\n",
            "Loss at  2500 th iteration is :  0.6928690075874329\n",
            "Loss at  3000 th iteration is :  0.6973711252212524\n",
            "Loss at  3500 th iteration is :  0.6942503452301025\n",
            "Loss at  4000 th iteration is :  0.6943045258522034\n",
            "Loss at  4500 th iteration is :  0.6942758560180664\n",
            "Loss at  5000 th iteration is :  0.6952133178710938\n",
            "Loss at  5500 th iteration is :  0.6908915638923645\n",
            "Loss at  6000 th iteration is :  0.6942387819290161\n",
            "Loss at  6500 th iteration is :  0.6930270195007324\n",
            "Loss at  7000 th iteration is :  0.6942485570907593\n",
            "Epoch  2  is starting...\n",
            "__________________________________\n",
            "Loss at  0 th iteration is :  0.6926306486129761\n",
            "Loss at  500 th iteration is :  0.9436832666397095\n",
            "Loss at  1000 th iteration is :  0.7611795663833618\n",
            "Loss at  1500 th iteration is :  0.7128462195396423\n",
            "Loss at  2000 th iteration is :  0.7208403944969177\n",
            "Loss at  2500 th iteration is :  0.6821414232254028\n",
            "Loss at  3000 th iteration is :  0.6740569472312927\n",
            "Loss at  3500 th iteration is :  0.6503923535346985\n",
            "Loss at  4000 th iteration is :  0.7149799466133118\n",
            "Loss at  4500 th iteration is :  0.7149555087089539\n",
            "Loss at  5000 th iteration is :  0.6218371987342834\n",
            "Loss at  5500 th iteration is :  0.7128145694732666\n",
            "Loss at  6000 th iteration is :  0.7108375430107117\n",
            "Loss at  6500 th iteration is :  0.698455810546875\n",
            "Loss at  7000 th iteration is :  0.6791021823883057\n",
            "Total loss in this epoch is  =  5002.982347007841\n",
            "Loss at  0 th iteration is :  0.697503387928009\n",
            "Loss at  500 th iteration is :  0.6976308822631836\n",
            "Loss at  1000 th iteration is :  0.693705141544342\n",
            "Loss at  1500 th iteration is :  0.6948245763778687\n",
            "Loss at  0 th iteration is :  0.6939257979393005\n",
            "Loss at  500 th iteration is :  0.6908730864524841\n",
            "Loss at  1000 th iteration is :  0.6925855278968811\n",
            "Loss at  1500 th iteration is :  0.6909699440002441\n",
            "Loss at  2000 th iteration is :  0.691758394241333\n",
            "Loss at  2500 th iteration is :  0.6885514855384827\n",
            "Loss at  3000 th iteration is :  0.6925753951072693\n",
            "Loss at  3500 th iteration is :  0.6926230192184448\n",
            "Loss at  4000 th iteration is :  0.6926348209381104\n",
            "Loss at  4500 th iteration is :  0.6926354169845581\n",
            "Loss at  5000 th iteration is :  0.6926347017288208\n",
            "Loss at  5500 th iteration is :  0.6959676146507263\n",
            "Loss at  6000 th iteration is :  0.6924670934677124\n",
            "Loss at  6500 th iteration is :  0.6946220397949219\n",
            "Loss at  7000 th iteration is :  0.6926361322402954\n",
            "Epoch  3  is starting...\n",
            "__________________________________\n",
            "Loss at  0 th iteration is :  0.6939257979393005\n",
            "Loss at  500 th iteration is :  0.8827552199363708\n",
            "Loss at  1000 th iteration is :  0.8553969264030457\n",
            "Loss at  1500 th iteration is :  0.7169336080551147\n",
            "Loss at  2000 th iteration is :  0.6533671617507935\n",
            "Loss at  2500 th iteration is :  0.6860306262969971\n",
            "Loss at  3000 th iteration is :  0.6685492396354675\n",
            "Loss at  3500 th iteration is :  0.6453699469566345\n",
            "Loss at  4000 th iteration is :  0.7420735359191895\n",
            "Loss at  4500 th iteration is :  0.7345982193946838\n",
            "Loss at  5000 th iteration is :  0.6703081727027893\n",
            "Loss at  5500 th iteration is :  0.7189906239509583\n",
            "Loss at  6000 th iteration is :  0.7616289854049683\n",
            "Loss at  6500 th iteration is :  0.6975210905075073\n",
            "Loss at  7000 th iteration is :  0.6822097897529602\n",
            "Total loss in this epoch is  =  5002.442560896976\n",
            "Loss at  0 th iteration is :  0.7153204679489136\n",
            "Loss at  500 th iteration is :  0.6973730325698853\n",
            "Loss at  1000 th iteration is :  0.6772603988647461\n",
            "Loss at  1500 th iteration is :  0.6850428581237793\n",
            "Loss at  0 th iteration is :  0.6910586953163147\n",
            "Loss at  500 th iteration is :  0.6769684553146362\n",
            "Loss at  1000 th iteration is :  0.6791138648986816\n",
            "Loss at  1500 th iteration is :  0.694115400314331\n",
            "Loss at  2000 th iteration is :  0.7462102174758911\n",
            "Loss at  2500 th iteration is :  0.6888115406036377\n",
            "Loss at  3000 th iteration is :  0.6769986748695374\n",
            "Loss at  3500 th iteration is :  0.679210364818573\n",
            "Loss at  4000 th iteration is :  0.6773335337638855\n",
            "Loss at  4500 th iteration is :  0.6770330667495728\n",
            "Loss at  5000 th iteration is :  0.6865143775939941\n",
            "Loss at  5500 th iteration is :  0.7049869894981384\n",
            "Loss at  6000 th iteration is :  0.6829695701599121\n",
            "Loss at  6500 th iteration is :  0.7005000114440918\n",
            "Loss at  7000 th iteration is :  0.6985746026039124\n",
            "Epoch  4  is starting...\n",
            "__________________________________\n",
            "Loss at  0 th iteration is :  0.6910586953163147\n",
            "Loss at  500 th iteration is :  0.8246011734008789\n",
            "Loss at  1000 th iteration is :  0.7581571936607361\n",
            "Loss at  1500 th iteration is :  0.7247073650360107\n",
            "Loss at  2000 th iteration is :  0.9113529324531555\n",
            "Loss at  2500 th iteration is :  0.7034732103347778\n",
            "Loss at  3000 th iteration is :  0.6654093265533447\n",
            "Loss at  3500 th iteration is :  0.6144737005233765\n",
            "Loss at  4000 th iteration is :  0.7898755073547363\n",
            "Loss at  4500 th iteration is :  0.7104798555374146\n",
            "Loss at  5000 th iteration is :  0.6789875030517578\n",
            "Loss at  5500 th iteration is :  0.7732998728752136\n",
            "Loss at  6000 th iteration is :  0.8532407283782959\n",
            "Loss at  6500 th iteration is :  0.6901313066482544\n",
            "Loss at  7000 th iteration is :  0.7066773176193237\n",
            "Total loss in this epoch is  =  4988.768140383996\n",
            "Loss at  0 th iteration is :  0.7568121552467346\n",
            "Loss at  500 th iteration is :  0.6211943626403809\n",
            "Loss at  1000 th iteration is :  0.6793736815452576\n",
            "Loss at  1500 th iteration is :  0.6896401047706604\n",
            "Loss at  0 th iteration is :  0.6411705017089844\n",
            "Loss at  500 th iteration is :  0.6511666178703308\n",
            "Loss at  1000 th iteration is :  0.7545347809791565\n",
            "Loss at  1500 th iteration is :  0.7409653067588806\n",
            "Loss at  2000 th iteration is :  0.805330216884613\n",
            "Loss at  2500 th iteration is :  0.6901787519454956\n",
            "Loss at  3000 th iteration is :  0.6533663868904114\n",
            "Loss at  3500 th iteration is :  0.6509318351745605\n",
            "Loss at  4000 th iteration is :  0.6998395919799805\n",
            "Loss at  4500 th iteration is :  0.6847712993621826\n",
            "Loss at  5000 th iteration is :  0.7255534529685974\n",
            "Loss at  5500 th iteration is :  0.696946918964386\n",
            "Loss at  6000 th iteration is :  0.637744128704071\n",
            "Loss at  6500 th iteration is :  0.6637460589408875\n",
            "Loss at  7000 th iteration is :  0.7272025942802429\n",
            "Epoch  5  is starting...\n",
            "__________________________________\n",
            "Loss at  0 th iteration is :  0.6411705017089844\n",
            "Loss at  500 th iteration is :  0.6756095290184021\n",
            "Loss at  1000 th iteration is :  0.6989116072654724\n",
            "Loss at  1500 th iteration is :  0.7059558033943176\n",
            "Loss at  2000 th iteration is :  0.5915549397468567\n",
            "Loss at  2500 th iteration is :  0.7000247240066528\n",
            "Loss at  3000 th iteration is :  0.710594654083252\n",
            "Loss at  3500 th iteration is :  0.6830613613128662\n",
            "Loss at  4000 th iteration is :  0.7246673703193665\n",
            "Loss at  4500 th iteration is :  0.6955835819244385\n",
            "Loss at  5000 th iteration is :  0.6787521243095398\n",
            "Loss at  5500 th iteration is :  0.6648144721984863\n",
            "Loss at  6000 th iteration is :  0.7677175998687744\n",
            "Loss at  6500 th iteration is :  0.6633210778236389\n",
            "Loss at  7000 th iteration is :  0.6913312673568726\n",
            "Total loss in this epoch is  =  4995.942988693714\n",
            "Loss at  0 th iteration is :  0.7575938701629639\n",
            "Loss at  500 th iteration is :  0.7330001592636108\n",
            "Loss at  1000 th iteration is :  0.6359326243400574\n",
            "Loss at  1500 th iteration is :  0.7720755338668823\n",
            "Loss at  0 th iteration is :  0.6142293214797974\n",
            "Loss at  500 th iteration is :  0.6720591187477112\n",
            "Loss at  1000 th iteration is :  0.6808176040649414\n",
            "Loss at  1500 th iteration is :  0.8122606873512268\n",
            "Loss at  2000 th iteration is :  0.7538197636604309\n",
            "Loss at  2500 th iteration is :  0.6548112034797668\n",
            "Loss at  3000 th iteration is :  0.6807176470756531\n",
            "Loss at  3500 th iteration is :  0.7467480897903442\n",
            "Loss at  4000 th iteration is :  0.7462587356567383\n",
            "Loss at  4500 th iteration is :  0.7462397813796997\n",
            "Loss at  5000 th iteration is :  0.7470483183860779\n",
            "Loss at  5500 th iteration is :  0.583619236946106\n",
            "Loss at  6000 th iteration is :  0.6386286616325378\n",
            "Loss at  6500 th iteration is :  0.5823385715484619\n",
            "Loss at  7000 th iteration is :  0.7797086238861084\n",
            "Epoch  6  is starting...\n",
            "__________________________________\n",
            "Loss at  0 th iteration is :  0.6142293214797974\n",
            "Loss at  500 th iteration is :  0.6943485736846924\n",
            "Loss at  1000 th iteration is :  0.758274257183075\n",
            "Loss at  1500 th iteration is :  0.6704217791557312\n",
            "Loss at  2000 th iteration is :  0.2618243992328644\n",
            "Loss at  2500 th iteration is :  0.4341907203197479\n",
            "Loss at  3000 th iteration is :  0.668987512588501\n",
            "Loss at  3500 th iteration is :  0.6567631363868713\n",
            "Loss at  4000 th iteration is :  0.6745873689651489\n",
            "Loss at  4500 th iteration is :  0.668134331703186\n",
            "Loss at  5000 th iteration is :  0.7225387096405029\n",
            "Loss at  5500 th iteration is :  0.6919560432434082\n",
            "Loss at  6000 th iteration is :  0.7053620219230652\n",
            "Loss at  6500 th iteration is :  0.5824858546257019\n",
            "Loss at  7000 th iteration is :  0.6697410345077515\n",
            "Total loss in this epoch is  =  4977.446785971522\n",
            "Loss at  0 th iteration is :  0.8138233423233032\n",
            "Loss at  500 th iteration is :  0.7961808443069458\n",
            "Loss at  1000 th iteration is :  0.6447978019714355\n",
            "Loss at  1500 th iteration is :  0.6097844839096069\n",
            "Loss at  0 th iteration is :  0.54900723695755\n",
            "Loss at  500 th iteration is :  0.6515535116195679\n",
            "Loss at  1000 th iteration is :  0.6633729338645935\n",
            "Loss at  1500 th iteration is :  0.8889596462249756\n",
            "Loss at  2000 th iteration is :  0.8146814703941345\n",
            "Loss at  2500 th iteration is :  0.6333070993423462\n",
            "Loss at  3000 th iteration is :  0.703750491142273\n",
            "Loss at  3500 th iteration is :  0.7413207292556763\n",
            "Loss at  4000 th iteration is :  0.8433091044425964\n",
            "Loss at  4500 th iteration is :  0.7374926209449768\n",
            "Loss at  5000 th iteration is :  0.8121848702430725\n",
            "Loss at  5500 th iteration is :  0.6574788093566895\n",
            "Loss at  6000 th iteration is :  0.7191369533538818\n",
            "Loss at  6500 th iteration is :  0.5734502673149109\n",
            "Loss at  7000 th iteration is :  0.729431688785553\n",
            "Epoch  7  is starting...\n",
            "__________________________________\n",
            "Loss at  0 th iteration is :  0.54900723695755\n",
            "Loss at  500 th iteration is :  0.8901968002319336\n",
            "Loss at  1000 th iteration is :  0.8521909117698669\n",
            "Loss at  1500 th iteration is :  0.6414163708686829\n",
            "Loss at  2000 th iteration is :  0.15077762305736542\n",
            "Loss at  2500 th iteration is :  0.550807774066925\n",
            "Loss at  3000 th iteration is :  0.678714394569397\n",
            "Loss at  3500 th iteration is :  0.6602111458778381\n",
            "Loss at  4000 th iteration is :  0.6988718509674072\n",
            "Loss at  4500 th iteration is :  0.6851409077644348\n",
            "Loss at  5000 th iteration is :  0.7924510836601257\n",
            "Loss at  5500 th iteration is :  0.6684933304786682\n",
            "Loss at  6000 th iteration is :  0.5074108242988586\n",
            "Loss at  6500 th iteration is :  0.639491081237793\n",
            "Loss at  7000 th iteration is :  0.6655686497688293\n",
            "Total loss in this epoch is  =  4942.056082658448\n",
            "Loss at  0 th iteration is :  0.8161760568618774\n",
            "Loss at  500 th iteration is :  0.7718846201896667\n",
            "Loss at  1000 th iteration is :  0.6260473728179932\n",
            "Loss at  1500 th iteration is :  0.5281078219413757\n",
            "Loss at  0 th iteration is :  0.4434661269187927\n",
            "Loss at  500 th iteration is :  0.6282776594161987\n",
            "Loss at  1000 th iteration is :  0.7218604683876038\n",
            "Loss at  1500 th iteration is :  2.083503484725952\n",
            "Loss at  2000 th iteration is :  1.1137069463729858\n",
            "Loss at  2500 th iteration is :  0.8737608194351196\n",
            "Loss at  3000 th iteration is :  0.6951888203620911\n",
            "Loss at  3500 th iteration is :  0.6729865670204163\n",
            "Loss at  4000 th iteration is :  0.7795016169548035\n",
            "Loss at  4500 th iteration is :  0.8218033909797668\n",
            "Loss at  5000 th iteration is :  0.6658807992935181\n",
            "Loss at  5500 th iteration is :  0.47993138432502747\n",
            "Loss at  6000 th iteration is :  0.6203427910804749\n",
            "Loss at  6500 th iteration is :  0.4922027587890625\n",
            "Loss at  7000 th iteration is :  0.7239382266998291\n",
            "Epoch  8  is starting...\n",
            "__________________________________\n",
            "Loss at  0 th iteration is :  0.4434661269187927\n",
            "Loss at  500 th iteration is :  0.7548550367355347\n",
            "Loss at  1000 th iteration is :  1.2414947748184204\n",
            "Loss at  1500 th iteration is :  0.4194622337818146\n",
            "Loss at  2000 th iteration is :  0.14545686542987823\n",
            "Loss at  2500 th iteration is :  0.6125514507293701\n",
            "Loss at  3000 th iteration is :  0.6705834269523621\n",
            "Loss at  3500 th iteration is :  0.6690201163291931\n",
            "Loss at  4000 th iteration is :  0.6986748576164246\n",
            "Loss at  4500 th iteration is :  0.6842608451843262\n",
            "Loss at  5000 th iteration is :  0.8187164068222046\n",
            "Loss at  5500 th iteration is :  0.583668053150177\n",
            "Loss at  6000 th iteration is :  0.4414684474468231\n",
            "Loss at  6500 th iteration is :  0.4711987376213074\n",
            "Loss at  7000 th iteration is :  0.7681941390037537\n",
            "Total loss in this epoch is  =  4933.784180503149\n",
            "Loss at  0 th iteration is :  0.7890481948852539\n",
            "Loss at  500 th iteration is :  0.760951817035675\n",
            "Loss at  1000 th iteration is :  0.6464904546737671\n",
            "Loss at  1500 th iteration is :  0.4104396104812622\n",
            "Loss at  0 th iteration is :  0.285460501909256\n",
            "Loss at  500 th iteration is :  0.6229095458984375\n",
            "Loss at  1000 th iteration is :  0.8215730786323547\n",
            "Loss at  1500 th iteration is :  1.7948278188705444\n",
            "Loss at  2000 th iteration is :  1.2486577033996582\n",
            "Loss at  2500 th iteration is :  0.6669973731040955\n",
            "Loss at  3000 th iteration is :  0.7798317074775696\n",
            "Loss at  3500 th iteration is :  0.7806730270385742\n",
            "Loss at  4000 th iteration is :  0.8273591995239258\n",
            "Loss at  4500 th iteration is :  0.8140003681182861\n",
            "Loss at  5000 th iteration is :  0.7272160053253174\n",
            "Loss at  5500 th iteration is :  0.5894963145256042\n",
            "Loss at  6000 th iteration is :  0.5773687362670898\n",
            "Loss at  6500 th iteration is :  0.40002259612083435\n",
            "Loss at  7000 th iteration is :  0.7793267965316772\n",
            "Epoch  9  is starting...\n",
            "__________________________________\n",
            "Loss at  0 th iteration is :  0.285460501909256\n",
            "Loss at  500 th iteration is :  0.7038471698760986\n",
            "Loss at  1000 th iteration is :  0.6900908946990967\n",
            "Loss at  1500 th iteration is :  0.5027721524238586\n",
            "Loss at  2000 th iteration is :  0.27890604734420776\n",
            "Loss at  2500 th iteration is :  0.6919480562210083\n",
            "Loss at  3000 th iteration is :  0.6869205236434937\n",
            "Loss at  3500 th iteration is :  0.6751106381416321\n",
            "Loss at  4000 th iteration is :  0.7258417010307312\n",
            "Loss at  4500 th iteration is :  0.6914156079292297\n",
            "Loss at  5000 th iteration is :  0.715787410736084\n",
            "Loss at  5500 th iteration is :  0.7107054591178894\n",
            "Loss at  6000 th iteration is :  0.3503650724887848\n",
            "Loss at  6500 th iteration is :  0.24221549928188324\n",
            "Loss at  7000 th iteration is :  0.6891122460365295\n",
            "Total loss in this epoch is  =  4880.3002413969025\n",
            "Loss at  0 th iteration is :  0.7945439219474792\n",
            "Loss at  500 th iteration is :  0.7980338931083679\n",
            "Loss at  1000 th iteration is :  0.6498140096664429\n",
            "Loss at  1500 th iteration is :  0.3284623920917511\n",
            "Loss at  0 th iteration is :  0.17175979912281036\n",
            "Loss at  500 th iteration is :  0.6344712972640991\n",
            "Loss at  1000 th iteration is :  0.6792726516723633\n",
            "Loss at  1500 th iteration is :  1.1881657838821411\n",
            "Loss at  2000 th iteration is :  1.0595488548278809\n",
            "Loss at  2500 th iteration is :  0.6701741814613342\n",
            "Loss at  3000 th iteration is :  0.6815060973167419\n",
            "Loss at  3500 th iteration is :  0.6688533425331116\n",
            "Loss at  4000 th iteration is :  0.7090229988098145\n",
            "Loss at  4500 th iteration is :  0.7037492990493774\n",
            "Loss at  5000 th iteration is :  0.8110790848731995\n",
            "Loss at  5500 th iteration is :  0.5140355825424194\n",
            "Loss at  6000 th iteration is :  0.5827754139900208\n",
            "Loss at  6500 th iteration is :  0.14565680921077728\n",
            "Loss at  7000 th iteration is :  0.768368124961853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekr0uf1jtkPx"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "f8Laqp-txEha",
        "outputId": "988c5aba-e911-4a52-c7ca-9f0baa9cd605"
      },
      "source": [
        "loss_train = training_loss\n",
        "loss_val = validation_loss\n",
        "loss_test = test_loss\n",
        "\n",
        "epochs = range(1, 11)\n",
        "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "#plt.plot(epochs, loss_test , 'r' , label = 'Test loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ovhB0rdRxMJy",
        "outputId": "2ce2c6ee-3d01-47c2-adc9-0a074d6952fa"
      },
      "source": [
        "acc_train = training_acc\n",
        "acc_val = validation_acc\n",
        "acc_test = test_acc\n",
        "\n",
        "epochs = range(1,11)\n",
        "plt.plot(epochs, acc_train, 'g', label='Training Acc')\n",
        "plt.plot(epochs, acc_val, 'b', label='validation Acc')\n",
        "#plt.plot(epochs, acc_test, 'r' , label = 'Test Acc')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QH_nZXJxWCV",
        "outputId": "ba35e579-b1c5-4751-f771-1c10e1392909"
      },
      "source": [
        "print(accuracy( test_data_tensor , test_label_tensor ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at  0 th iteration is :  0.8490163087844849\n",
            "Loss at  500 th iteration is :  0.8107059597969055\n",
            "Loss at  1000 th iteration is :  1.445365309715271\n",
            "Loss at  1500 th iteration is :  0.6460733413696289\n",
            "(1215.5463653504949, 0.4963898916967509)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Lla-xWDLmzc"
      },
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}